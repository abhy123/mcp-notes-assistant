{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1630c5-a722-43a8-9699-3a0452c12801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample notes: ['travel.txt', 'kubernetes.txt', '.ipynb_checkpoints', 'work_notes.txt', 'llm_research.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create notes directory\n",
    "os.makedirs(\"notes\", exist_ok=True)\n",
    "\n",
    "# Sample notes\n",
    "notes = {\n",
    "    \"kubernetes.txt\": \"\"\"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. \n",
    "It works well with Docker and supports service discovery, load balancing, and rolling updates.\"\"\",\n",
    "\n",
    "    \"llm_research.txt\": \"\"\"Large Language Models (LLMs) such as GPT-4 and LLaMA are being used for Retrieval-Augmented Generation (RAG), \n",
    "chatbots, and AI agents. Key challenges include hallucinations, latency, and cost management.\"\"\",\n",
    "\n",
    "    \"travel.txt\": \"\"\"Last summer I traveled to Himachal Pradesh and visited Manali, Kasol, and Dharamshala. \n",
    "The mountains were beautiful, and the weather was much cooler compared to Delhi.\"\"\",\n",
    "\n",
    "    \"work_notes.txt\": \"\"\"Tasks for next sprint:\n",
    "    - Finalize API Gateway migration to Gravitee\n",
    "    - Implement Kafka DLQ handling\n",
    "    - Review microservices scaling strategy\n",
    "    - Prepare staff engineer interview case study\"\"\"\n",
    "}\n",
    "\n",
    "# Write notes to files\n",
    "for fname, content in notes.items():\n",
    "    with open(os.path.join(\"mcp_a/notes\", fname), \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Created sample notes:\", os.listdir(\"mcp_a/notes\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "affa0a4a-dce7-4457-8627-5c6455227421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "[\n",
      "  {\n",
      "    \"name\": \"list_notes\",\n",
      "    \"title\": null,\n",
      "    \"description\": \"List all available notes in the notes folder.\",\n",
      "    \"inputSchema\": {\n",
      "      \"properties\": {},\n",
      "      \"title\": \"list_notesArguments\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"outputSchema\": null,\n",
      "    \"annotations\": null,\n",
      "    \"meta\": null\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"read_note\",\n",
      "    \"title\": null,\n",
      "    \"description\": \"Read the contents of a note.\",\n",
      "    \"inputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"filename\": {\n",
      "          \"title\": \"Filename\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"filename\"\n",
      "      ],\n",
      "      \"title\": \"read_noteArguments\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"outputSchema\": null,\n",
      "    \"annotations\": null,\n",
      "    \"meta\": null\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"search_notes\",\n",
      "    \"title\": null,\n",
      "    \"description\": \"Search for a keyword in all notes.\",\n",
      "    \"inputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"query\": {\n",
      "          \"title\": \"Query\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"query\"\n",
      "      ],\n",
      "      \"title\": \"search_notesArguments\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"outputSchema\": null,\n",
      "    \"annotations\": null,\n",
      "    \"meta\": null\n",
      "  }\n",
      "]\n",
      "\n",
      "Notes:\n",
      "{\n",
      "  \"meta\": null,\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"{\\n  \\\"notes\\\": [\\n    \\\"travel.txt\\\",\\n    \\\"kubernetes.txt\\\",\\n    \\\".ipynb_checkpoints\\\",\\n    \\\"work_notes.txt\\\",\\n    \\\"llm_research.txt\\\"\\n  ]\\n}\",\n",
      "      \"annotations\": null,\n",
      "      \"meta\": null\n",
      "    }\n",
      "  ],\n",
      "  \"structuredContent\": null,\n",
      "  \"isError\": false\n",
      "}\n",
      "\n",
      "Note content:\n",
      "{\n",
      "  \"meta\": null,\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"{\\n  \\\"content\\\": \\\"Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. \\\\nIt works well with Docker and supports service discovery, load balancing, and rolling updates.\\\"\\n}\",\n",
      "      \"annotations\": null,\n",
      "      \"meta\": null\n",
      "    }\n",
      "  ],\n",
      "  \"structuredContent\": null,\n",
      "  \"isError\": false\n",
      "}\n",
      "\n",
      "Search results:\n",
      "{\n",
      "  \"meta\": null,\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"{\\n  \\\"results\\\": [\\n    {\\n      \\\"file\\\": \\\"travel.txt\\\",\\n      \\\"snippet\\\": \\\"Last summer I traveled to Himachal Pradesh and visited Manali, Kasol, and Dharamshala. \\\\nThe mountains were beautiful, and the weather was much cooler compared to Delhi.\\\"\\n    }\\n  ]\\n}\",\n",
      "      \"annotations\": null,\n",
      "      \"meta\": null\n",
      "    }\n",
      "  ],\n",
      "  \"structuredContent\": null,\n",
      "  \"isError\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from agents.mcp import MCPServerStdio\n",
    "\n",
    "params = {\"command\": \"python\", \"args\": [\"mcp_a/notes_server.py\"]}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    # List tools (convert to dicts for JSON)\n",
    "    tools = await server.list_tools()\n",
    "    print(\"Available tools:\")\n",
    "    print(json.dumps([tool.model_dump() for tool in tools], indent=2))\n",
    "\n",
    "    # Call list_notes\n",
    "    notes = await server.call_tool(\"list_notes\", {})\n",
    "    print(\"\\nNotes:\")\n",
    "    print(json.dumps(notes.model_dump(), indent=2))\n",
    "\n",
    "    # Call read_note\n",
    "    note_content = await server.call_tool(\"read_note\", {\"filename\": \"kubernetes.txt\"})\n",
    "    print(\"\\nNote content:\")\n",
    "    print(json.dumps(note_content.model_dump(), indent=2))\n",
    "\n",
    "    # Call search_notes\n",
    "    search_result = await server.call_tool(\"search_notes\", {\"query\": \"himachal\"})\n",
    "    print(\"\\nSearch results:\")\n",
    "    print(json.dumps(search_result.model_dump(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "664eb9a0-804d-45e8-9c6d-88d5fdda368f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/22/25 16:39:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/responses</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 </span>  <a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1740</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">OK\"</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/22/25 16:39:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/responses\u001b[0m \u001b[32m\"HTTP/1.1 200 \u001b[0m  \u001b]8;id=649262;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=791250;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\u001b\\\u001b[2m1740\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mOK\"\u001b[0m                                                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/22/25 16:39:34] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/responses</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 </span>  <a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1740</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">OK\"</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/22/25 16:39:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/responses\u001b[0m \u001b[32m\"HTTP/1.1 200 \u001b[0m  \u001b]8;id=15736;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=374333;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\u001b\\\u001b[2m1740\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mOK\"\u001b[0m                                                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/22/25 16:39:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/traces/ingest</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 </span>  <a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">204 No Content\"</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/22/25 16:39:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/traces/ingest\u001b[0m \u001b[32m\"HTTP/1.1 \u001b[0m  \u001b]8;id=451469;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=296374;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m204 No Content\"\u001b[0m                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/22/25 16:39:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/responses</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 </span>  <a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1740</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">OK\"</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/22/25 16:39:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/responses\u001b[0m \u001b[32m\"HTTP/1.1 200 \u001b[0m  \u001b]8;id=640027;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=300647;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1740\u001b\\\u001b[2m1740\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mOK\"\u001b[0m                                                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output from Agent:\n",
      "\n",
      "Your notes mention that Large Language Models (LLMs) such as GPT-4 and LLaMA are being used for Retrieval-Augmented Generation (RAG), chatbots, and AI agents. Key challenges associated with these LLMs include hallucinations, latency, and cost management. If you want, I can help you find more detailed notes or related topics.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/22/25 16:39:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/traces/ingest</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 </span>  <a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">204 No Content\"</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/22/25 16:39:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/traces/ingest\u001b[0m \u001b[32m\"HTTP/1.1 \u001b[0m  \u001b]8;id=584107;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=384544;file:///opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m204 No Content\"\u001b[0m                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a helpful notes assistant.\n",
    "You can read, list, and search notes using the tools available.\n",
    "\"\"\"\n",
    "\n",
    "request = \"Find anything about LLMs in my notes and show me the content.\"\n",
    "\n",
    "params = {\"command\": \"python\", \"args\": [\"mcp_a/notes_server.py\"]}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(\n",
    "        name=\"notes_agent\",\n",
    "        instructions=instructions,\n",
    "        model=\"gpt-4.1-mini\",  # Your OpenAI model\n",
    "        mcp_servers=[mcp_server],\n",
    "    )\n",
    "    with trace(\"notes_agent\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    print(\"\\nFinal Output from Agent:\\n\")\n",
    "    print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb770a7a-9058-45b0-b185-0df8fc138b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
